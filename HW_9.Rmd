---
title: "**Homework 9**"
author: 
- "**Name:** Sofia Vaquera"
- "**UT EID:** sv27974"
- "**Github:** https://github.com/svaquera/HW-9"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Loads necessary libraries
library(tidyverse)
library(mosaic)
library(moderndive)
library(effectsize)

```

# Problem 1: Manufacturing Flaws in Circuit Boards

```{r, echo = FALSE}

# Imports solder dataset
solder = read.csv("solder.csv")

```

## Part A: Plotting Relationships

```{r, echo = FALSE}

# Plots relationship between size of the opening on the solder gun and the number of skips

ggplot(solder) + geom_boxplot(aes(x = Opening, y = skips)) + 
  labs(title = "Relationship Between Size of Solder Gun Opening and Number of Skips",
       x = "Size of Opening on Solder Gun", 
       y = "Number of SKips",
       caption = "The plot above shows the number of solder skips on a circuit board by the size of the opening on the solder \ngun (large, medium, or small, represented by the letters L, M, and S respectively). Small openings have the \nhighest median number of skips, while large openings having the lowest median number of skips.") + 
  theme(plot.caption = element_text(hjust = 0))

```

```{r, echo = FALSE}

# Plots relationship between thickness of alloy used for soldering and the number of skips

ggplot(solder) + geom_boxplot(aes(x = Solder, y = skips)) + 
  labs(title = "Relationship Between Thickness of Alloy Used for Soldering and \nNumber of Skips",
       x = "Thickness of Alloy Used for Soldering", 
       y = "Number of SKips",
       caption = "The plot above shows the number of solder skips on a circuit board by the thickness of the alloy used for \nsoldering (thick or thin). Thin openings have the highest median number of skips, while thin openings have \nthe lowest median number of skips.") + 
  theme(plot.caption = element_text(hjust = 0))

```

## Part B: Building a Regression Model

```{r, echo = FALSE}

solder_model = lm(skips ~ Opening + Solder + Opening:Solder, data = solder)
get_regression_table(solder_model, conf.level = 0.95, digits = 3)

```

## Part C: Interpreting Model Coefficients
```{r, include = FALSE}

# Returns regression equation coefficients
coef(solder_model) |>
  round(2)

```

The coefficients in the regression model constructed in Part B can be interpreted as follows:

* The baseline number of skips for circuit boards constructed using a solder gun with a large opening and a thick alloy is 0.39 skips.

* The main effect for the `OpeningM` variable (circuit boards constructed using a solder gun with a medium opening) is 2.41 skips. This is the effect of `OpeningM` when the alloy used to construct the circuit board is thick rather than thin (i.e. there is no interaction between the `OpeningM` and `SolderThin` variables).

* The main effect for the `OpeningS` variable (circuit boards constructed using a solder gun with a small opening) is 5.13 skips. This is the effect of `OpeningS` when the alloy used to construct the circuit board is thick rather than thin (i.e. there is no interaction between the `OpeningS` and `SolderThin` variables).

* The main effect for the `SolderThin` variable (circuit boards constructed using a thin alloy) is 2.28 skips. This is the effect of `SolderThin` in isolation.

* The interaction effect for `OpeningM` and `SolderThin` is -0.74. This effectively means that circuit boards that are constructed using a solder gun with a medium opening and a thin alloy have 0.74 fewer skips on average than what you would expect from summing the individual "isolated" effects of the two variables.

* The interaction effect for `OpeningS` and `SolderThin` is 9.65. This effectively means that circuit boards that are constructed using a solder gun with a small  opening and a thin alloy have 9.65 more skips on average than what you would expect from summing the individual "isolated" effects of the two variables.

## Part D: Optimal Combination

If I had to recommend a combination of `Opening` size and `Solder` thickness to minimize the number of skips in the manufacturing process, I would recommend using a solder gun with a large opening and a thick alloy. This is because circuit boards constructed using a solder gun with a large opening and a thick alloy had, on average, 0.39 skips, which is the lowest number of skips for any of the combinations of `Opening` size and `Solder` thickness.


# Problem 2: Grocery Store Prices

```{r, echo = FALSE}

# Imports groceries dataset
groceries = read.csv("groceries.csv")


```

## Part A: Price Differences Across Stores

The following is a bar plot of price differences across different stores where there is no differentiation between the Austin and Houston locations for Whole Foods and H-E-B.

```{r, echo = FALSE}

# Finds average price of products sold by store
store_prices = groceries |>
  group_by(Store) |>
  summarize(avg_price = mean(Price))


# Plots average price of products sold by store
ggplot(store_prices) + geom_col(aes(x = Store, y = avg_price)) + 
  labs(title = "Average Price of Products Sold by Store",
       x = "Store", 
       y = "Average Price of Products Sold",
       caption = "The plot above shows the average price of products sold across several stores. The \nstore with the highest average price of products sold is Whole Foods, while the store \nwith the lowest average price of products sold is Fiesta.") + 
  theme(plot.caption = element_text(hjust = 0)) + 
  coord_flip()


```

## Part B: Variety of Items in Stores

```{r, echo = FALSE}

# Manipulates dataset to count the number of stores that offer a product
store_variety <- groceries |>
  mutate(Store = str_trim(Store)) |>
  mutate(Store = if_else(Store == "Whole Foods" | Store == "H-E-B", paste(Store, City, sep = " - "), Store)) |>
  group_by(Store, Product) |>
  group_by(Product) |>
  summarize(count = n())

# Plots number of stores selling a certain product
ggplot(store_variety) + geom_col(aes(x = Product, y = count)) + 
  labs(title = "Number of Stores Selling a Certain Product",
       x = "Product", 
       y = "Number of Stores Selling Product",
       caption = "The plot above shows the number of stores selling a given product. The items that are sold in \nthe most number of stores (in this case, all 16 stores observed) are Horizon 2% Milk Carton \nand Carton of eggs, while the items that are sold in the least number of stores (4 stores) are \nCinnamon Toast Crunch 1 lb, El Milagros Tortilla Chips, Frosted Flakes 1 lb, and Lucky \nCharms 1 lb.") + 
  theme(plot.caption = element_text(hjust = 0)) + 
  coord_flip() + 
  theme(axis.text.y = element_text(size = 5, hjust = 1))


```

## Part C: Price by Product and Store Type

```{r, echo = FALSE}

# Creates a regression model for price by product and store type
groceries_model = lm(Price ~ Product + Type, data = groceries)
get_regression_table(groceries_model, conf.level = 0.95, digits = 2)

```

Compared with ordinary grocery stores (like Albertsons, HEB, or Krogers), convenience stores charge somewhere between 0.41 dollars and 0.92 dollars more for the same product.



## Part D: Price by Product and Store

```{r, echo = FALSE}

# Creates a regression model for price by product and store type
groceries_model2 = lm(Price ~ Product + Store, data = groceries)
get_regression_table(groceries_model2, conf.level = 0.95, digits = 2)

```

The two stores that seem to charge the lowest prices when comparing the same product are Walmart (0.99 dollars below the baseline) and Kroger Fresh Fare (0.90 dollars below the baseline). The two stores that seem to charge the highest prices when comparing the same product are Whole Foods (0.36 dollars above the baseline) and Wheatsville Food Co-Op (0.29 dollars above the baseline).


## Part E: Pricing at Central Market vs HEB

Based on the coefficients of the model from Part D, it seems more probable that Central Market charges a similar amount to HEB for the same product. The estimate for the price of some product at HEB is 0.65 dollars below the baseline, while the price of the same product at Central Market is 0.57 dollars below the baseline. This means that there is a difference of about 0.08 dollars between the price of a product as HEB vs Central Market. This difference is small relative to differences among other stores. For instance, the difference in price for a product at Walmart (which is a Grocery store like HEB) and the same product at Whole Foods (which is a High-End Grocery store like Central Market) is about 1.35 dollars, which effectively means that Whole Foods sells the same product for 1.35 dollars more than Walmart. This reinforces that there is a relatively small difference in the prices for a product at HEB vs Central Market. Another piece of evidence in support of the argument that Central Market charges a similar amount to HEB for the same product is the confidence intervals for the estimates of the coefficients; the 95% confidence interval for Central Market is between -0.92 and -0.23 dollars, while the 95% confidence interval for HEB is between -0.95 and -0.35 dollars Given that the intervals are so similar and that there's a large overlap between the two intervals, it's reasonable to say that Central Market charges a similar amount to HEB for the same product.


## Part F: Price by Product and Income10K

```{r, echo = FALSE}

# Updates groceries dataset to include Income10K variable
groceries = groceries |>
  mutate(Income10K = Income/10000)

# Creates a regression model for price by product and income10k
groceries_model3 = lm(Price ~ Product + Income10K, data = groceries)
get_regression_table(groceries_model3, conf.level = 0.95, digits = 2)


```


Based on the sign of the Income10K coefficient, consumers in poorer ZIP codes seem to pay more for the same product on average. This is evidenced by the Income10K coefficient being negative, which would mean that as Income10K increased, the amount subtracted from the baseline would increase, lowering the price. The reverse is also true; a negative coefficient for the Income10K variable would mean that as income decreases, the amount subtracted from the baseline would decrease, raising the price. Thus, this indicates that consumers in poorer ZIP codes seem to pay more for the same product.



```{r, echo = FALSE}

# z-scores all of the numerical variables in the model
standardize_parameters(groceries_model3)

```


A one-standard deviation increase in the income of a ZIP code seems to be associated with a 0.03 standard-deviation change in the price that consumers in that ZIP code expect to pay for the same product.

# Problem 3: Redlining

## Statement A: ZIP codes with a higher percentage of minority residents tend to have more FAIR policies per 100 housing units.

This statement is **true**. This is evidenced by Figure A1, which shows a positive correlation between the percentage of minority residents in a ZIP code and the number of FAIR policies per 100 housing units. This figure demonstrates that ZIP codes with higher percentages of minority residents tend to have more FAIR policies per 100 housing units.

## Statement B: The evidence suggests an interaction effect between minority percentage and the age of the housing stock in the way that these two variables are related to the number of FAIR policies in a ZIP code.


This statement is **undecidable / ambiguous**. Figure A1 and Figure B1 show the relationship between the percentage of minority residents in a ZIP code and the number of FAIR policies per 100 housing units and the relationship between the percentage of housing units built before WWII and the percentage of minority residents respectively. Given that both of the aforementioned relationships have positive correlations, meaning that as the percentage of housing units built before WWII increases, so does the percentage of minority residents, and as the percentage of minority residents increases, so does the FAIR policies per 100 housing units, it's seems plausible that there could be an interaction between minority percentage and age of the housing stock. However, the value of R^2 for Figure B1 is relatively low, indicating that most of the variation in the minority percentage can't be predicted using the percentage of housing built before WWII. To be more certain of any potential interaction, it would be helpful to have evidence of the confidence interval for an interaction coefficient, which would help us to determine whether or not any interaction actually occurs.



## Statement C: The relationship between minority percentage and number of FAIR policies per 100 housing units is stronger in high-fire-risk ZIP codes than in low-fire-risk ZIP codes.

This statement is **true**. This is evidenced by Figure C1, which shows the relationship between minority percentage and number of FAIR policies per 100 housing units by whether they are in the high or low fire risk groups. The regression table shows that the baseline, where the fire risk is high and the minority percentage is 0, is 0.544. The coefficient for the minority variable is 0.01, indicating that the relationship gets stronger between minority percentage and FAIR policies per 100 housing units as the minority percentage increases in the high fire risk group. However, the coefficient for the low fire risk variable is -0.443, which indicates a lower intercept for the low fire risk group. Furthermore, the interaction between the minority variable and the low fire risk variable is -0.001, meaning that the rate at which the strength of the relationship between minority percentage and FAIR policies per 100 Housing Units is 0.01 lower in the low fire risk group than the high fire risk group. Therefore, it is reasonable to say that the relationship between minority percentage and number of FAIR policies per 100 housing units is stronger in high-fire-risk ZIP codes than in low-fire-risk ZIP codes.


## Statement D: Even without controlling for any other variables, income “explains away” all the association between minority percentage and FAIR policy uptake.

This statement is **false**. This is evidenced by model D1 and model D2. Model D1 shows that when you regress FAIR policies on minority percentage alone, the coefficient for the minority variable is 0.014. Meanwhile, Model D2 shows that when you add median income as a control, the minority coefficient decreases slightly to 0.01. While there is a slight decrease in the minority coefficient when median income is added to the regression model as a control, it is misleadiing to say that the income variable by itself "explains away" **all** of the association between minority percentage and FAIR policy uptake. It would be more accurate to say the income variable accounts for the some of what initially seemed to be an association between minority percentage and FAIR policy uptake, meaning that the income variable is able to "explain away" some, but not all, of this association.


## Statement E: Minority percentage and number of FAIR policies are still associated at the ZIP code level, even after controlling for income, fire risk, and housing age.

This statement is **true**. This is evidenced by model E, which is a multiple linear regression model that controls for income, fire risk, and housing age, in addition to the minority percentage. The coefficient for the minority variable in this model is 0.008, which indicates that there is still an association between minority percentage and the number of FAIR policies at the ZIP code level even after controlling for income, fire risk, and housing age. 


